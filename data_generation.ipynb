{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a8742b",
   "metadata": {},
   "source": [
    "# Generaci√≥n de Datos sint√©ticos de entrenamiento para el nano language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d6d9a",
   "metadata": {},
   "source": [
    "El nano language model, desde ahora en adelante NLM, es un modelo de lenguaje especializado en transformar lenguaje natural en formulas de l√≥gica proposicional. Para entrenar este modelo, es necesario contar con un conjunto de datos de entrenamiento que contenga ejemplos de lenguaje natural y sus correspondientes formulas de l√≥gica proposicional. Para esto le pediremos a un LLM m√°s grande, como GPT-4 o DeepSeek R1 que nos genere nuestro dataset de entrenamiento sint√©tico.\n",
    "\n",
    "Para esto usaremos Pydantic AI para usar la api de DeepSeek R1 usando la modalidad de JSON Output, lo que nos permitir√° generar un dataset de entrenamiento estructurado y f√°cil de usar para entrenar nuestro NLM.\n",
    "\n",
    "La estructura de nuestro dataset de entrenamiento ser√° la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8219bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"$defs\": {\n",
       "    \"AtomDefinition\": {\n",
       "      \"description\": \"Mapeo entre una letra proposicional y su significado en lenguaje natural.\",\n",
       "      \"properties\": {\n",
       "        \"atom\": {\n",
       "          \"description\": \"La letra que representa la proposici√≥n (ejemplo: p, q, r...).\",\n",
       "          \"pattern\": \"^[a-z]$\",\n",
       "          \"title\": \"Atom\",\n",
       "          \"type\": \"string\"\n",
       "        },\n",
       "        \"definition\": {\n",
       "          \"description\": \"La proposici√≥n simple en lenguaje natural que representa el √°tomo.\",\n",
       "          \"title\": \"Definition\",\n",
       "          \"type\": \"string\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"atom\",\n",
       "        \"definition\"\n",
       "      ],\n",
       "      \"title\": \"AtomDefinition\",\n",
       "      \"type\": \"object\"\n",
       "    },\n",
       "    \"Complexity\": {\n",
       "      \"description\": \"Nivel de complejidad de la proposici√≥n.\",\n",
       "      \"enum\": [\n",
       "        \"simple\",\n",
       "        \"intermediate\",\n",
       "        \"advanced\"\n",
       "      ],\n",
       "      \"title\": \"Complexity\",\n",
       "      \"type\": \"string\"\n",
       "    },\n",
       "    \"ConnectorUsage\": {\n",
       "      \"description\": \"Registro de un conector l√≥gico usado y la frase que lo activ√≥.\",\n",
       "      \"properties\": {\n",
       "        \"connector\": {\n",
       "          \"$ref\": \"#/$defs/LogicalConnector\",\n",
       "          \"description\": \"El conector l√≥gico identificado.\"\n",
       "        },\n",
       "        \"natural_language_cue\": {\n",
       "          \"description\": \"La palabra o frase en el texto original que indica este conector (ejemplo: 'y', 'si...entonces', 'o', 'no es cierto que').\",\n",
       "          \"title\": \"Natural Language Cue\",\n",
       "          \"type\": \"string\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"connector\",\n",
       "        \"natural_language_cue\"\n",
       "      ],\n",
       "      \"title\": \"ConnectorUsage\",\n",
       "      \"type\": \"object\"\n",
       "    },\n",
       "    \"LogicalConnector\": {\n",
       "      \"description\": \"Conectores l√≥gicos est√°ndar de la l√≥gica proposicional.\",\n",
       "      \"enum\": [\n",
       "        \"¬¨\",\n",
       "        \"‚àß\",\n",
       "        \"‚à®\",\n",
       "        \"‚Üí\",\n",
       "        \"‚Üî\"\n",
       "      ],\n",
       "      \"title\": \"LogicalConnector\",\n",
       "      \"type\": \"string\"\n",
       "    },\n",
       "    \"PropositionalFormula\": {\n",
       "      \"description\": \"La f√≥rmula final en l√≥gica proposicional.\",\n",
       "      \"properties\": {\n",
       "        \"formula\": {\n",
       "          \"description\": \"La f√≥rmula en l√≥gica proposicional usando s√≠mbolos est√°ndar (ejemplo: (p ‚àß q) ‚Üí r).\",\n",
       "          \"title\": \"Formula\",\n",
       "          \"type\": \"string\"\n",
       "        },\n",
       "        \"formula_ascii\": {\n",
       "          \"description\": \"La misma f√≥rmula usando notaci√≥n ASCII (ejemplo: (p & q) -> r).\",\n",
       "          \"title\": \"Formula Ascii\",\n",
       "          \"type\": \"string\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"formula\",\n",
       "        \"formula_ascii\"\n",
       "      ],\n",
       "      \"title\": \"PropositionalFormula\",\n",
       "      \"type\": \"object\"\n",
       "    },\n",
       "    \"ReasoningStep\": {\n",
       "      \"description\": \"Un paso individual en el proceso de razonamiento.\",\n",
       "      \"properties\": {\n",
       "        \"step\": {\n",
       "          \"description\": \"N√∫mero secuencial del paso de razonamiento.\",\n",
       "          \"title\": \"Step\",\n",
       "          \"type\": \"integer\"\n",
       "        },\n",
       "        \"explanation\": {\n",
       "          \"description\": \"Descripci√≥n t√©cnica de lo que se est√° analizando en este punto del razonamiento.\",\n",
       "          \"title\": \"Explanation\",\n",
       "          \"type\": \"string\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"step\",\n",
       "        \"explanation\"\n",
       "      ],\n",
       "      \"title\": \"ReasoningStep\",\n",
       "      \"type\": \"object\"\n",
       "    },\n",
       "    \"ThoughtBlock\": {\n",
       "      \"description\": \"Bloque de razonamiento completo: an√°lisis paso a paso del texto.\",\n",
       "      \"properties\": {\n",
       "        \"reasoning_steps\": {\n",
       "          \"description\": \"Secuencia de pasos de razonamiento para descomponer el texto en l√≥gica proposicional.\",\n",
       "          \"items\": {\n",
       "            \"$ref\": \"#/$defs/ReasoningStep\"\n",
       "          },\n",
       "          \"title\": \"Reasoning Steps\",\n",
       "          \"type\": \"array\"\n",
       "        },\n",
       "        \"identified_atoms\": {\n",
       "          \"description\": \"Lista de √°tomos proposicionales identificados en el texto.\",\n",
       "          \"items\": {\n",
       "            \"$ref\": \"#/$defs/AtomDefinition\"\n",
       "          },\n",
       "          \"title\": \"Identified Atoms\",\n",
       "          \"type\": \"array\"\n",
       "        },\n",
       "        \"identified_connectors\": {\n",
       "          \"description\": \"Lista de conectores l√≥gicos identificados junto con su pista en el texto original.\",\n",
       "          \"items\": {\n",
       "            \"$ref\": \"#/$defs/ConnectorUsage\"\n",
       "          },\n",
       "          \"title\": \"Identified Connectors\",\n",
       "          \"type\": \"array\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"reasoning_steps\",\n",
       "        \"identified_atoms\",\n",
       "        \"identified_connectors\"\n",
       "      ],\n",
       "      \"title\": \"ThoughtBlock\",\n",
       "      \"type\": \"object\"\n",
       "    },\n",
       "    \"TrainingExample\": {\n",
       "      \"description\": \"Un ejemplo completo de entrenamiento: texto natural ‚Üí l√≥gica proposicional.\",\n",
       "      \"properties\": {\n",
       "        \"natural_language_input\": {\n",
       "          \"description\": \"El enunciado o argumento en lenguaje natural que se debe formalizar.\",\n",
       "          \"title\": \"Natural Language Input\",\n",
       "          \"type\": \"string\"\n",
       "        },\n",
       "        \"complexity\": {\n",
       "          \"$ref\": \"#/$defs/Complexity\",\n",
       "          \"description\": \"Nivel de complejidad del ejemplo.\"\n",
       "        },\n",
       "        \"thought\": {\n",
       "          \"$ref\": \"#/$defs/ThoughtBlock\",\n",
       "          \"description\": \"Bloque de pensamiento con el razonamiento paso a paso (chain-of-thought).\"\n",
       "        },\n",
       "        \"output\": {\n",
       "          \"$ref\": \"#/$defs/PropositionalFormula\",\n",
       "          \"description\": \"La f√≥rmula proposicional resultante.\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"natural_language_input\",\n",
       "        \"complexity\",\n",
       "        \"thought\",\n",
       "        \"output\"\n",
       "      ],\n",
       "      \"title\": \"TrainingExample\",\n",
       "      \"type\": \"object\"\n",
       "    }\n",
       "  },\n",
       "  \"description\": \"Dataset sint√©tico de entrenamiento para el NLM.\",\n",
       "  \"properties\": {\n",
       "    \"examples\": {\n",
       "      \"description\": \"Lista de ejemplos de entrenamiento para transformar lenguaje natural en l√≥gica proposicional.\",\n",
       "      \"items\": {\n",
       "        \"$ref\": \"#/$defs/TrainingExample\"\n",
       "      },\n",
       "      \"title\": \"Examples\",\n",
       "      \"type\": \"array\"\n",
       "    }\n",
       "  },\n",
       "  \"required\": [\n",
       "    \"examples\"\n",
       "  ],\n",
       "  \"title\": \"SyntheticDataset\",\n",
       "  \"type\": \"object\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from IPython.display import Markdown\n",
    "import json\n",
    "\n",
    "\n",
    "# --- Enums para valores controlados ---\n",
    "\n",
    "\n",
    "class LogicalConnector(str, Enum):\n",
    "    \"\"\"Conectores l√≥gicos est√°ndar de la l√≥gica proposicional.\"\"\"\n",
    "    NEGATION = \"¬¨\"  # NOT\n",
    "    CONJUNCTION = \"‚àß\"  # AND\n",
    "    DISJUNCTION = \"‚à®\"  # OR\n",
    "    IMPLICATION = \"‚Üí\"  # IF...THEN\n",
    "    BICONDITIONAL = \"‚Üî\"\n",
    "\n",
    "\n",
    "class Complexity(str, Enum):\n",
    "    \"\"\"Nivel de complejidad de la proposici√≥n.\"\"\"\n",
    "\n",
    "    SIMPLE = \"simple\"  # 1-2 √°tomos, 1 conector\n",
    "    INTERMEDIATE = \"intermediate\"  # 2-3 √°tomos, 2-3 conectores\n",
    "    ADVANCED = \"advanced\"  # 3+ √°tomos, conectores anidados\n",
    "\n",
    "\n",
    "# --- Sub-modelos ---\n",
    "\n",
    "\n",
    "class ReasoningStep(BaseModel):\n",
    "    \"\"\"Un paso individual en el proceso de razonamiento.\"\"\"\n",
    "\n",
    "    step: int = Field(description=\"N√∫mero secuencial del paso de razonamiento.\")\n",
    "    explanation: str = Field(\n",
    "        description=\"Descripci√≥n t√©cnica de lo que se est√° analizando en este punto del razonamiento.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AtomDefinition(BaseModel):\n",
    "    \"\"\"Mapeo entre una letra proposicional y su significado en lenguaje natural.\"\"\"\n",
    "\n",
    "    atom: str = Field(\n",
    "        description=\"La letra que representa la proposici√≥n (ejemplo: p, q, r...).\",\n",
    "        pattern=r\"^[a-z]$\",\n",
    "    )\n",
    "    definition: str = Field(\n",
    "        description=\"La proposici√≥n simple en lenguaje natural que representa el √°tomo.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ConnectorUsage(BaseModel):\n",
    "    \"\"\"Registro de un conector l√≥gico usado y la frase que lo activ√≥.\"\"\"\n",
    "\n",
    "    connector: LogicalConnector = Field(description=\"El conector l√≥gico identificado.\")\n",
    "    natural_language_cue: str = Field(\n",
    "        description=\"La palabra o frase en el texto original que indica este conector (ejemplo: 'y', 'si...entonces', 'o', 'no es cierto que').\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Bloque de pensamiento (chain-of-thought) ---\n",
    "\n",
    "\n",
    "class ThoughtBlock(BaseModel):\n",
    "    \"\"\"Bloque de razonamiento completo: an√°lisis paso a paso del texto.\"\"\"\n",
    "\n",
    "    reasoning_steps: list[ReasoningStep] = Field(\n",
    "        description=\"Secuencia de pasos de razonamiento para descomponer el texto en l√≥gica proposicional.\"\n",
    "    )\n",
    "    identified_atoms: list[AtomDefinition] = Field(\n",
    "        description=\"Lista de √°tomos proposicionales identificados en el texto.\"\n",
    "    )\n",
    "    identified_connectors: list[ConnectorUsage] = Field(\n",
    "        description=\"Lista de conectores l√≥gicos identificados junto con su pista en el texto original.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Resultado final ---\n",
    "\n",
    "\n",
    "class PropositionalFormula(BaseModel):\n",
    "    \"\"\"La f√≥rmula final en l√≥gica proposicional.\"\"\"\n",
    "\n",
    "    formula: str = Field(\n",
    "        description=\"La f√≥rmula en l√≥gica proposicional usando s√≠mbolos est√°ndar (ejemplo: (p ‚àß q) ‚Üí r).\"\n",
    "    )\n",
    "    formula_ascii: str = Field(\n",
    "        description=\"La misma f√≥rmula usando notaci√≥n ASCII (ejemplo: (p & q) -> r).\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Ejemplo de entrenamiento completo ---\n",
    "\n",
    "\n",
    "class TrainingExample(BaseModel):\n",
    "    \"\"\"Un ejemplo completo de entrenamiento: texto natural ‚Üí l√≥gica proposicional.\"\"\"\n",
    "\n",
    "    natural_language_input: str = Field(\n",
    "        description=\"El enunciado o argumento en lenguaje natural que se debe formalizar.\"\n",
    "    )\n",
    "    complexity: Complexity = Field(description=\"Nivel de complejidad del ejemplo.\")\n",
    "    thought: ThoughtBlock = Field(\n",
    "        description=\"Bloque de pensamiento con el razonamiento paso a paso (chain-of-thought).\"\n",
    "    )\n",
    "    output: PropositionalFormula = Field(\n",
    "        description=\"La f√≥rmula proposicional resultante.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Dataset completo ---\n",
    "\n",
    "\n",
    "class SyntheticDataset(BaseModel):\n",
    "    \"\"\"Dataset sint√©tico de entrenamiento para el NLM.\"\"\"\n",
    "\n",
    "    examples: list[TrainingExample] = Field(\n",
    "        description=\"Lista de ejemplos de entrenamiento para transformar lenguaje natural en l√≥gica proposicional.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Visualizar el JSON Schema con syntax highlighting\n",
    "schema_json = json.dumps(SyntheticDataset.model_json_schema(), indent=2, ensure_ascii=False)\n",
    "Markdown(f\"```json\\n{schema_json}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441de5d6",
   "metadata": {},
   "source": [
    "Con el JSON Schema anterior, definimos la estructura de nuestro dataset de entrenamiento, que consiste en una lista de ejemplos, donde cada ejemplo contiene un enunciado en lenguaje natural y su correspondiente formula de l√≥gica proposicional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50c728",
   "metadata": {},
   "source": [
    "## Configuraci√≥n del Agente de Generaci√≥n\n",
    "\n",
    "Configuramos el agente de Pydantic AI con DeepSeek como proveedor. Cargamos la API key desde el archivo `.env` y definimos el system prompt que guiar√° al modelo en la generaci√≥n de ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321bef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key cargada correctamente ‚úì\n",
      "Agente configurado correctamente ‚úì\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# Cargar variables de entorno desde .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar que la API key est√° configurada\n",
    "assert os.getenv(\"DEEPSEEK_API_KEY\"), \"DEEPSEEK_API_KEY no encontrada en .env\"\n",
    "print(\"API Key cargada correctamente ‚úì\")\n",
    "\n",
    "# System prompt especializado en dev/hacking/cybersec\n",
    "SYSTEM_PROMPT = \"\"\"Eres un experto en l√≥gica proposicional especializado en ciberseguridad, desarrollo de software y hacking √©tico.\n",
    "\n",
    "Tu tarea es generar ejemplos de entrenamiento que transformen enunciados t√©cnicos en lenguaje natural\n",
    "a f√≥rmulas de l√≥gica proposicional.\n",
    "\n",
    "DOMINIOS TEM√ÅTICOS (var√≠a entre estos):\n",
    "- üîì Ciberseguridad: reglas de firewall, detecci√≥n de intrusos, an√°lisis de vulnerabilidades, pol√≠ticas de acceso\n",
    "- üêõ Pentesting/CTF: condiciones de exploit, escalaci√≥n de privilegios, movimiento lateral, exfiltraci√≥n\n",
    "- üíª Programaci√≥n: validaciones, flujos de control, condiciones de error, l√≥gica de negocio\n",
    "- üñ•Ô∏è Sysadmin: reglas de red, permisos Unix, configuraci√≥n de servicios, monitoreo\n",
    "- üöÄ DevOps/CI-CD: pipelines, condiciones de deploy, rollbacks, health checks\n",
    "- üéÆ Game hacking: manipulaci√≥n de memoria, bypass de anticheat, condiciones de win/lose\n",
    "\n",
    "REGLAS:\n",
    "1. Los enunciados deben sonar como los dir√≠a un dev/hacker real, con jerga t√©cnica natural.\n",
    "   Ejemplo: \"Si el puerto 443 est√° abierto y el certificado SSL ha expirado, entonces el servidor es vulnerable a MITM\"\n",
    "2. Usa correctamente los conectores l√≥gicos:\n",
    "   - \"y\", \"adem√°s\", \"siempre que ambos\" ‚Üí ‚àß (conjunci√≥n)\n",
    "   - \"o\", \"ya sea\", \"cualquiera de\" ‚Üí ‚à® (disyunci√≥n)\n",
    "   - \"si...entonces\", \"implica\", \"cuando\", \"siempre que\" ‚Üí ‚Üí (implicaci√≥n)\n",
    "   - \"si y solo si\", \"equivale a\", \"√∫nicamente cuando\" ‚Üí ‚Üî (bicondicional)\n",
    "   - \"no\", \"no es cierto que\", \"falla\", \"no est√°\" ‚Üí ¬¨ (negaci√≥n)\n",
    "3. Los √°tomos deben ser letras min√∫sculas (p, q, r, s, t...).\n",
    "4. Las f√≥rmulas deben usar par√©ntesis para desambiguar precedencia.\n",
    "5. Genera una mezcla de complejidades: simple, intermediate y advanced.\n",
    "6. El razonamiento (thought) debe ser detallado paso a paso, explicando la l√≥gica t√©cnica.\n",
    "7. Proporciona tanto la f√≥rmula con s√≠mbolos Unicode (‚àß, ‚à®, ‚Üí, ‚Üî, ¬¨) como en ASCII (&, |, ->, <->, ~).\n",
    "8. Genera los enunciados en espa√±ol, pero permite t√©rminos t√©cnicos en ingl√©s cuando sea natural\n",
    "   (ej: \"firewall\", \"buffer overflow\", \"SQL injection\", \"deploy\", \"rollback\").\n",
    "9. NO generes enunciados gen√©ricos aburridos. Cada ejemplo debe sentirse como algo que un profesional dir√≠a en su d√≠a a d√≠a.\n",
    "\"\"\"\n",
    "\n",
    "# Crear el agente con DeepSeek\n",
    "agent = Agent(\n",
    "    \"deepseek:deepseek-chat\",\n",
    "    output_type=SyntheticDataset,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "print(\"Agente configurado correctamente ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36e66b",
   "metadata": {},
   "source": [
    "## Generaci√≥n del Dataset\n",
    "\n",
    "Generamos el dataset en lotes (batches) para evitar timeouts y poder ir guardando progreso. Cada lote le pide al modelo 5 ejemplos con una mezcla de complejidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9af96d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pathlib\n",
    "\n",
    "\n",
    "# --- Configuraci√≥n de generaci√≥n ---\n",
    "TOTAL_EXAMPLES = 50\n",
    "EXAMPLES_PER_BATCH = 1     # Reducido para evitar OOM\n",
    "OUTPUT_FILE = \"dataset.json\"\n",
    "\n",
    "# Temas especializados en dev/hacking/cybersec\n",
    "TOPICS = [\n",
    "    \"reglas de firewall y filtrado de paquetes (iptables, WAF, ACLs)\",\n",
    "    \"pentesting y explotaci√≥n de vulnerabilidades (SQLi, XSS, RCE, SSRF)\",\n",
    "    \"escalaci√≥n de privilegios en Linux (SUID, capabilities, kernel exploits)\",\n",
    "    \"CTF challenges (crypto, reversing, pwn, web)\",\n",
    "    \"validaciones y sanitizaci√≥n de input en APIs REST\",\n",
    "    \"flujos de autenticaci√≥n y autorizaci√≥n (OAuth, JWT, RBAC)\",\n",
    "    \"configuraci√≥n de redes y segmentaci√≥n (VLANs, subnets, VPN)\",\n",
    "    \"pipelines CI/CD y condiciones de deploy (GitHub Actions, Jenkins)\",\n",
    "    \"monitoreo y alertas de seguridad (SIEM, IDS/IPS, logs)\",\n",
    "    \"game hacking y anti-cheat (memory manipulation, packet tampering)\",\n",
    "    \"hardening de servidores y buenas pr√°cticas sysadmin\",\n",
    "    \"an√°lisis de malware y condiciones de ejecuci√≥n de payloads\",\n",
    "    \"l√≥gica de negocio en aplicaciones web (e-commerce, banking)\",\n",
    "    \"permisos Unix y control de acceso (chmod, chown, sudo, SELinux)\",\n",
    "    \"condiciones de error handling y excepciones en c√≥digo\",\n",
    "]\n",
    "\n",
    "all_examples: list[TrainingExample] = []\n",
    "\n",
    "# Cargar progreso previo si existe\n",
    "if pathlib.Path(OUTPUT_FILE).exists():\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        prev = SyntheticDataset.model_validate_json(f.read())\n",
    "        all_examples = prev.examples\n",
    "        print(f\"üìÇ Cargados {len(all_examples)} ejemplos previos\")\n",
    "\n",
    "async def generate_batch(topic: str, complexity_mix: str) -> list[TrainingExample]:\n",
    "    \"\"\"Genera un lote de ejemplos de entrenamiento.\"\"\"\n",
    "    prompt = f\"\"\"Genera exactamente {EXAMPLES_PER_BATCH} ejemplos de entrenamiento sobre: {topic}.\n",
    "\n",
    "Mezcla de complejidades para este lote: {complexity_mix}.\n",
    "\n",
    "Cada ejemplo debe tener:\n",
    "- Un enunciado que suene como algo que dir√≠a un dev o hacker en su d√≠a a d√≠a\n",
    "- Razonamiento detallado paso a paso con contexto t√©cnico\n",
    "- Identificaci√≥n correcta de √°tomos y conectores\n",
    "- La f√≥rmula proposicional correcta en Unicode y ASCII\n",
    "\n",
    "¬°S√© creativo y t√©cnicamente preciso! Usa jerga real del campo.\"\"\"\n",
    "\n",
    "    result = await agent.run(prompt)\n",
    "    return result.output.examples\n",
    "\n",
    "def save_progress():\n",
    "    \"\"\"Guarda el progreso actual a disco.\"\"\"\n",
    "    dataset = SyntheticDataset(examples=all_examples)\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(dataset.model_dump_json(indent=2))\n",
    "\n",
    "async def generate_dataset():\n",
    "    \"\"\"Genera el dataset completo en lotes con guardado incremental.\"\"\"\n",
    "    remaining = TOTAL_EXAMPLES - len(all_examples)\n",
    "    num_batches = remaining // EXAMPLES_PER_BATCH\n",
    "\n",
    "    if num_batches == 0:\n",
    "        print(\"‚úÖ Ya se alcanz√≥ el total de ejemplos deseado\")\n",
    "        return\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        topic = random.choice(TOPICS)\n",
    "        complexity_mixes = [\n",
    "            \"2 simple, 1 intermediate\",\n",
    "            \"1 simple, 2 intermediate\",\n",
    "            \"1 intermediate, 2 advanced\",\n",
    "            \"1 simple, 1 intermediate, 1 advanced\",\n",
    "            \"2 intermediate, 1 advanced\",\n",
    "        ]\n",
    "        mix = complexity_mixes[i % len(complexity_mixes)]\n",
    "\n",
    "        print(f\"üîÑ Lote {i+1}/{num_batches} | Tema: {topic[:50]}... | Mix: {mix}\")\n",
    "\n",
    "        try:\n",
    "            examples = await generate_batch(topic, mix)\n",
    "            all_examples.extend(examples)\n",
    "            save_progress()  # Guardar despu√©s de cada lote\n",
    "            print(f\"   ‚úÖ +{len(examples)} ejemplos (total: {len(all_examples)}) [guardado]\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error en lote {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nüéâ Generaci√≥n completada: {len(all_examples)} ejemplos en total\")\n",
    "\n",
    "await generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1805cd",
   "metadata": {},
   "source": [
    "## Guardar Dataset\n",
    "\n",
    "Guardamos el dataset generado en formato JSON para usarlo en el entrenamiento del NLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Guardar el dataset en JSON\n",
    "dataset = SyntheticDataset(examples=all_examples)\n",
    "dataset_json = dataset.model_dump_json(indent=2)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dataset_json)\n",
    "\n",
    "print(f\"‚úÖ Dataset guardado en {OUTPUT_FILE}\")\n",
    "print(f\"üìä Total de ejemplos: {len(all_examples)}\")\n",
    "\n",
    "# Mostrar estad√≠sticas\n",
    "complexities = Counter(ex.complexity.value for ex in all_examples)\n",
    "print(\"\\nüìà Distribuci√≥n por complejidad:\")\n",
    "for comp, count in complexities.most_common():\n",
    "    print(f\"   {comp}: {count} ejemplos\")\n",
    "\n",
    "# Mostrar un ejemplo\n",
    "print(\"\\nüìù Ejemplo aleatorio:\")\n",
    "sample = random.choice(all_examples)\n",
    "print(f\"   Input: {sample.natural_language_input}\")\n",
    "print(f\"   F√≥rmula: {sample.output.formula}\")\n",
    "print(f\"   ASCII: {sample.output.formula_ascii}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-language-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
