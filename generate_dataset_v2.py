"""
Generador de dataset sint√©tico v2 - Usa OpenAI SDK directo con DeepSeek.
Sin tool calling, sin Pydantic AI. JSON en prompt ‚Üí parseo manual.

Uso:
    python generate_dataset_v2.py
    python generate_dataset_v2.py --total 500
"""

import json
import os
import random
import pathlib
import argparse
import gc
import time
import re

from dotenv import load_dotenv
from openai import OpenAI

# --- Cargar .env ---
load_dotenv()
assert os.getenv("DEEPSEEK_API_KEY"), "‚ùå DEEPSEEK_API_KEY no encontrada en .env"

# --- Cliente DeepSeek (compatible con OpenAI SDK) ---
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com",
)

# =============================================
# SCHEMA DE EJEMPLO (como string para el prompt)
# =============================================

JSON_SCHEMA = """{
  "natural_language_input": "string - enunciado t√©cnico en espa√±ol",
  "complexity": "simple | intermediate | advanced",
  "thought": {
    "reasoning_steps": [
      {"step": 1, "explanation": "string - paso de razonamiento"}
    ],
    "identified_atoms": [
      {"atom": "p", "definition": "string - proposici√≥n que representa"},
      {"atom": "q", "definition": "string - proposici√≥n que representa"},
      {"atom": "r", "definition": "string - proposici√≥n que representa"}
      {"atom": "s", "definition": "string - proposici√≥n que representa"},
      {"atom": "t", "definition": "string - proposici√≥n que representa"},
      {"atom": "u", "definition": "string - proposici√≥n que representa"}
      ... (los √°tomos deben ser letras min√∫sculas y su definici√≥n debe ser clara y t√©cnica) ...
    ],
    "identified_connectors": [
      {"connector": "‚Üí", "natural_language_cue": "string - palabra clave"}
    ]
  },
  "output": {
    "formula": "string - f√≥rmula con s√≠mbolos Unicode (¬¨, ‚àß, ‚à®, ‚Üí, ‚Üî)",
    "formula_ascii": "string - f√≥rmula ASCII (~, &, |, ->, <->)"
  }
}"""

# =============================================
# CONFIGURACI√ìN
# =============================================

SYSTEM_PROMPT = """Eres un experto en l√≥gica proposicional especializado en ciberseguridad, desarrollo de software y hacking √©tico.

Tu tarea es generar ejemplos de entrenamiento que transformen enunciados t√©cnicos en lenguaje natural
a f√≥rmulas de l√≥gica proposicional.

DOMINIOS TEM√ÅTICOS (var√≠a entre estos):
- üîì Ciberseguridad: reglas de firewall, detecci√≥n de intrusos, an√°lisis de vulnerabilidades, pol√≠ticas de acceso
- üêõ Pentesting/CTF: condiciones de exploit, escalaci√≥n de privilegios, movimiento lateral, exfiltraci√≥n
- üíª Programaci√≥n: validaciones, flujos de control, condiciones de error, l√≥gica de negocio
- üñ•Ô∏è Sysadmin: reglas de red, permisos Unix, configuraci√≥n de servicios, monitoreo
- üöÄ DevOps/CI-CD: pipelines, condiciones de deploy, rollbacks, health checks
- üéÆ Game hacking: manipulaci√≥n de memoria, bypass de anticheat, condiciones de win/lose

REGLAS:
1. Los enunciados deben sonar como los dir√≠a un dev/hacker real, con jerga t√©cnica natural.
   Ejemplo: "Si el puerto 443 est√° abierto y el certificado SSL ha expirado, entonces el servidor es vulnerable a MITM"
2. Usa correctamente los conectores l√≥gicos:
   - "y", "adem√°s", "siempre que ambos" ‚Üí ‚àß (conjunci√≥n)
   - "o", "ya sea", "cualquiera de" ‚Üí ‚à® (disyunci√≥n)
   - "si...entonces", "implica", "cuando", "siempre que" ‚Üí ‚Üí (implicaci√≥n)
   - "si y solo si", "equivale a", "√∫nicamente cuando" ‚Üí ‚Üî (bicondicional)
   - "no", "no es cierto que", "falla", "no est√°" ‚Üí ¬¨ (negaci√≥n)
3. Los √°tomos deben ser letras min√∫sculas (p, q, r, s, t...).
4. Las f√≥rmulas deben usar par√©ntesis para desambiguar precedencia.
5. Genera una mezcla de complejidades: simple, intermediate y advanced.
6. El razonamiento (thought) debe ser detallado paso a paso, explicando la l√≥gica t√©cnica.
7. Proporciona tanto la f√≥rmula con s√≠mbolos Unicode (‚àß, ‚à®, ‚Üí, ‚Üî, ¬¨) como en ASCII (&, |, ->, <->, ~).
8. Genera los enunciados en espa√±ol, pero permite t√©rminos t√©cnicos en ingl√©s cuando sea natural
   (ej: "firewall", "buffer overflow", "SQL injection", "deploy", "rollback").
9. NO generes enunciados gen√©ricos aburridos. Cada ejemplo debe sentirse como algo que un profesional dir√≠a en su d√≠a a d√≠a.

IMPORTANTE: Responde √öNICAMENTE con JSON v√°lido, sin markdown, sin ```json, sin explicaciones extra."""

TOPICS = [
    "reglas de firewall y filtrado de paquetes (iptables, WAF, ACLs)",
    "pentesting y explotaci√≥n de vulnerabilidades (SQLi, XSS, RCE, SSRF)",
    "escalaci√≥n de privilegios en Linux (SUID, capabilities, kernel exploits)",
    "CTF challenges (crypto, reversing, pwn, web)",
    "validaciones y sanitizaci√≥n de input en APIs REST",
    "flujos de autenticaci√≥n y autorizaci√≥n (OAuth, JWT, RBAC)",
    "configuraci√≥n de redes y segmentaci√≥n (VLANs, subnets, VPN)",
    "pipelines CI/CD y condiciones de deploy (GitHub Actions, Jenkins)",
    "monitoreo y alertas de seguridad (SIEM, IDS/IPS, logs)",
    "game hacking y anti-cheat (memory manipulation, packet tampering)",
    "hardening de servidores y buenas pr√°cticas sysadmin",
    "an√°lisis de malware y condiciones de ejecuci√≥n de payloads",
    "l√≥gica de negocio en aplicaciones web (e-commerce, banking)",
    "permisos Unix y control de acceso (chmod, chown, sudo, SELinux)",
    "condiciones de error handling y excepciones en c√≥digo",
]

COMPLEXITIES = ["simple", "intermediate", "advanced"]


# =============================================
# FUNCIONES
# =============================================


def load_progress(output_file: str) -> list[dict]:
    """Carga ejemplos previos del archivo si existe."""
    path = pathlib.Path(output_file)
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                data = json.loads(content)
                return data.get("examples", [])
    return []


def save_progress(examples: list[dict], output_file: str):
    """Guarda el progreso actual a disco."""
    dataset = {"examples": examples}
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)


def extract_json(text: str) -> dict | None:
    """Extrae JSON de la respuesta, limpiando markdown si hay."""
    # Quitar bloques de c√≥digo markdown
    text = text.strip()
    if text.startswith("```"):
        text = re.sub(r"^```(?:json)?\s*\n?", "", text)
        text = re.sub(r"\n?```\s*$", "", text)
        text = text.strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError:
        # Intentar encontrar JSON dentro del texto
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            try:
                return json.loads(match.group())
            except json.JSONDecodeError:
                pass
    return None


def validate_example(example: dict) -> bool:
    """Validaci√≥n b√°sica de un ejemplo."""
    required = ["natural_language_input", "complexity", "thought", "output"]
    if not all(k in example for k in required):
        return False
    if not isinstance(example.get("thought"), dict):
        return False
    if not isinstance(example.get("output"), dict):
        return False
    if "formula" not in example["output"]:
        return False
    return True


def generate_one(topic: str, complexity: str) -> dict | None:
    """Genera un ejemplo llamando a DeepSeek directamente."""
    prompt = f"""Genera exactamente 1 ejemplo de entrenamiento sobre: {topic}.

Complejidad: {complexity}.

El ejemplo debe seguir este schema JSON exacto:
{JSON_SCHEMA}

Responde SOLO con el JSON del ejemplo, nada m√°s."""

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            temperature=0.9,
            max_tokens=2000,
            timeout=120,
        )

        text = response.choices[0].message.content
        example = extract_json(text)

        if example and validate_example(example):
            # Normalizar complexity
            if example.get("complexity") not in COMPLEXITIES:
                example["complexity"] = complexity
            return example
        else:
            return None

    except Exception as e:
        raise e


def main():
    parser = argparse.ArgumentParser(
        description="Genera dataset sint√©tico de l√≥gica proposicional (v2 - directo)"
    )
    parser.add_argument(
        "--total", type=int, default=50, help="Total de ejemplos a generar"
    )
    parser.add_argument(
        "--output", type=str, default="dataset.json", help="Archivo de salida"
    )
    args = parser.parse_args()

    output_file = args.output
    total = args.total

    # Cargar progreso previo
    all_examples = load_progress(output_file)
    if all_examples:
        print(f"üìÇ Cargados {len(all_examples)} ejemplos previos desde {output_file}")

    remaining = total - len(all_examples)
    if remaining <= 0:
        print(f"‚úÖ Ya tienes {len(all_examples)}/{total} ejemplos. Nada que generar.")
        return

    print(f"üöÄ Generando {remaining} ejemplos restantes (objetivo: {total})")
    print(f"üìÅ Guardando en: {output_file}")
    print(f"üí∞ Costo estimado: ~${remaining * 0.002:.2f} USD\n")

    errors = 0
    consecutive_errors = 0
    start_time = time.time()

    for i in range(remaining):
        if len(all_examples) >= total:
            break

        topic = random.choice(TOPICS)
        complexity = random.choice(COMPLEXITIES)

        print(
            f"üîÑ [{len(all_examples) + 1}/{total}] {topic[:55]}... ({complexity})",
            end=" ",
            flush=True,
        )

        try:
            example = generate_one(topic, complexity)
            if example:
                all_examples.append(example)
                save_progress(all_examples, output_file)
                print("‚úÖ")
                consecutive_errors = 0
            else:
                errors += 1
                consecutive_errors += 1
                print(f"‚ö†Ô∏è JSON inv√°lido ({consecutive_errors}/10)")

        except Exception as e:
            errors += 1
            consecutive_errors += 1
            err_str = str(e)
            is_rate_limit = "429" in err_str or "rate limit" in err_str.lower()
            if is_rate_limit:
                wait = 10 * consecutive_errors
                print(f"‚è≥ Rate limit, esperando {wait}s...")
                time.sleep(wait)
            else:
                print(f"‚ùå ({consecutive_errors}/10) {err_str[:80]}")

        if consecutive_errors >= 10:
            print("\n‚ö†Ô∏è 10 errores consecutivos, deteniendo.")
            break

        # Liberar memoria cada 20 ejemplos
        if (i + 1) % 20 == 0:
            gc.collect()

        # Pausa m√≠nima entre llamadas
        time.sleep(1)

    # Resumen final
    elapsed = time.time() - start_time
    generated = len(all_examples) - (total - remaining - errors)
    print(f"\n{'=' * 60}")
    print(f"üéâ Generaci√≥n completada!")
    print(f"üìä Total: {len(all_examples)} ejemplos")
    print(f"‚ùå Errores: {errors}")
    print(f"‚è±Ô∏è  Tiempo: {elapsed / 60:.1f} minutos")
    print(f"üìÅ Guardado en: {output_file}")

    # Estad√≠sticas
    from collections import Counter

    complexities = Counter(ex.get("complexity", "?") for ex in all_examples)
    print(f"\nüìà Distribuci√≥n:")
    for comp, count in complexities.most_common():
        print(f"   {comp}: {count}")

    if all_examples:
        sample = random.choice(all_examples)
        print(f"\nüìù Ejemplo aleatorio:")
        print(f"   Input: {sample['natural_language_input']}")
        print(f"   F√≥rmula: {sample['output']['formula']}")
        print(f"   ASCII: {sample['output']['formula_ascii']}")


if __name__ == "__main__":
    main()
