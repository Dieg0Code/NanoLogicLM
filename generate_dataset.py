"""
Script standalone para generar el dataset sintÃ©tico de entrenamiento.
Corre fuera del notebook para evitar OOM del kernel de Jupyter.

Uso:
    python generate_dataset.py
    python generate_dataset.py --total 100 --batch-size 3
"""

import asyncio
import json
import os
import random
import pathlib
import argparse
import gc
import time
from enum import Enum

from dotenv import load_dotenv
from pydantic import BaseModel, Field
from pydantic_ai import Agent

# --- Cargar .env ---
load_dotenv()
assert os.getenv("DEEPSEEK_API_KEY"), "âŒ DEEPSEEK_API_KEY no encontrada en .env"


# =============================================
# MODELOS PYDANTIC (mismos del notebook)
# =============================================


class LogicalConnector(str, Enum):
    NEGATION = "Â¬"
    CONJUNCTION = "âˆ§"
    DISJUNCTION = "âˆ¨"
    IMPLICATION = "â†’"
    BICONDITIONAL = "â†”"


class Complexity(str, Enum):
    SIMPLE = "simple"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"


class ReasoningStep(BaseModel):
    step: int = Field(description="NÃºmero secuencial del paso de razonamiento.")
    explanation: str = Field(
        description="DescripciÃ³n tÃ©cnica de lo que se estÃ¡ analizando en este punto del razonamiento."
    )


class AtomDefinition(BaseModel):
    atom: str = Field(
        description="La letra que representa la proposiciÃ³n (ejemplo: p, q, r...).",
        pattern=r"^[a-z][0-9]?$",
    )
    definition: str = Field(
        description="La proposiciÃ³n simple en lenguaje natural que representa el Ã¡tomo."
    )


class ConnectorUsage(BaseModel):
    connector: str = Field(
        description="El conector lÃ³gico identificado (Â¬, âˆ§, âˆ¨, â†’, â†”)."
    )
    natural_language_cue: str = Field(
        description="La palabra o frase en el texto original que indica este conector."
    )


class ThoughtBlock(BaseModel):
    reasoning_steps: list[ReasoningStep] = Field(
        description="Secuencia de pasos de razonamiento."
    )
    identified_atoms: list[AtomDefinition] = Field(
        description="Lista de Ã¡tomos proposicionales identificados."
    )
    identified_connectors: list[ConnectorUsage] = Field(
        description="Lista de conectores lÃ³gicos identificados."
    )


class PropositionalFormula(BaseModel):
    formula: str = Field(
        description="La fÃ³rmula en lÃ³gica proposicional usando sÃ­mbolos estÃ¡ndar."
    )
    formula_ascii: str = Field(description="La misma fÃ³rmula usando notaciÃ³n ASCII.")


class TrainingExample(BaseModel):
    natural_language_input: str = Field(
        description="El enunciado en lenguaje natural que se debe formalizar."
    )
    complexity: Complexity = Field(description="Nivel de complejidad del ejemplo.")
    thought: ThoughtBlock = Field(
        description="Bloque de pensamiento con el razonamiento paso a paso."
    )
    output: PropositionalFormula = Field(
        description="La fÃ³rmula proposicional resultante."
    )


class SyntheticDataset(BaseModel):
    examples: list[TrainingExample] = Field(
        description="Lista de ejemplos de entrenamiento."
    )


# =============================================
# CONFIGURACIÃ“N DEL AGENTE
# =============================================

SYSTEM_PROMPT = """Eres un experto en lÃ³gica proposicional especializado en ciberseguridad, desarrollo de software y hacking Ã©tico.

Tu tarea es generar ejemplos de entrenamiento que transformen enunciados tÃ©cnicos en lenguaje natural
a fÃ³rmulas de lÃ³gica proposicional.

DOMINIOS TEMÃTICOS (varÃ­a entre estos):
- ğŸ”“ Ciberseguridad: reglas de firewall, detecciÃ³n de intrusos, anÃ¡lisis de vulnerabilidades, polÃ­ticas de acceso
- ğŸ› Pentesting/CTF: condiciones de exploit, escalaciÃ³n de privilegios, movimiento lateral, exfiltraciÃ³n
- ğŸ’» ProgramaciÃ³n: validaciones, flujos de control, condiciones de error, lÃ³gica de negocio
- ğŸ–¥ï¸ Sysadmin: reglas de red, permisos Unix, configuraciÃ³n de servicios, monitoreo
- ğŸš€ DevOps/CI-CD: pipelines, condiciones de deploy, rollbacks, health checks
- ğŸ® Game hacking: manipulaciÃ³n de memoria, bypass de anticheat, condiciones de win/lose

REGLAS:
1. Los enunciados deben sonar como los dirÃ­a un dev/hacker real, con jerga tÃ©cnica natural.
   Ejemplo: "Si el puerto 443 estÃ¡ abierto y el certificado SSL ha expirado, entonces el servidor es vulnerable a MITM"
2. Usa correctamente los conectores lÃ³gicos:
   - "y", "ademÃ¡s", "siempre que ambos" â†’ âˆ§ (conjunciÃ³n)
   - "o", "ya sea", "cualquiera de" â†’ âˆ¨ (disyunciÃ³n)
   - "si...entonces", "implica", "cuando", "siempre que" â†’ â†’ (implicaciÃ³n)
   - "si y solo si", "equivale a", "Ãºnicamente cuando" â†’ â†” (bicondicional)
   - "no", "no es cierto que", "falla", "no estÃ¡" â†’ Â¬ (negaciÃ³n)
3. Los Ã¡tomos deben ser letras minÃºsculas (p, q, r, s, t...).
4. Las fÃ³rmulas deben usar parÃ©ntesis para desambiguar precedencia.
5. Genera una mezcla de complejidades: simple, intermediate y advanced.
6. El razonamiento (thought) debe ser detallado paso a paso, explicando la lÃ³gica tÃ©cnica.
7. Proporciona tanto la fÃ³rmula con sÃ­mbolos Unicode (âˆ§, âˆ¨, â†’, â†”, Â¬) como en ASCII (&, |, ->, <->, ~).
8. Genera los enunciados en espaÃ±ol, pero permite tÃ©rminos tÃ©cnicos en inglÃ©s cuando sea natural
   (ej: "firewall", "buffer overflow", "SQL injection", "deploy", "rollback").
9. NO generes enunciados genÃ©ricos aburridos. Cada ejemplo debe sentirse como algo que un profesional dirÃ­a en su dÃ­a a dÃ­a.
"""

TOPICS = [
    "reglas de firewall y filtrado de paquetes (iptables, WAF, ACLs)",
    "pentesting y explotaciÃ³n de vulnerabilidades (SQLi, XSS, RCE, SSRF)",
    "escalaciÃ³n de privilegios en Linux (SUID, capabilities, kernel exploits)",
    "CTF challenges (crypto, reversing, pwn, web)",
    "validaciones y sanitizaciÃ³n de input en APIs REST",
    "flujos de autenticaciÃ³n y autorizaciÃ³n (OAuth, JWT, RBAC)",
    "configuraciÃ³n de redes y segmentaciÃ³n (VLANs, subnets, VPN)",
    "pipelines CI/CD y condiciones de deploy (GitHub Actions, Jenkins)",
    "monitoreo y alertas de seguridad (SIEM, IDS/IPS, logs)",
    "game hacking y anti-cheat (memory manipulation, packet tampering)",
    "hardening de servidores y buenas prÃ¡cticas sysadmin",
    "anÃ¡lisis de malware y condiciones de ejecuciÃ³n de payloads",
    "lÃ³gica de negocio en aplicaciones web (e-commerce, banking)",
    "permisos Unix y control de acceso (chmod, chown, sudo, SELinux)",
    "condiciones de error handling y excepciones en cÃ³digo",
]

EXAMPLES_PER_BATCH = 1

COMPLEXITY_MIXES = [
    "simple",
    "intermediate",
    "advanced",
]


# =============================================
# FUNCIONES DE GENERACIÃ“N
# =============================================


def load_progress(output_file: str) -> list[TrainingExample]:
    """Carga ejemplos previos del archivo si existe."""
    path = pathlib.Path(output_file)
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                dataset = SyntheticDataset.model_validate_json(content)
                return list(dataset.examples)
    return []


def save_progress(examples: list[TrainingExample], output_file: str):
    """Guarda el progreso actual a disco."""
    dataset = SyntheticDataset(examples=examples)
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(dataset.model_dump_json(indent=2))


async def generate_one(
    agent: Agent, topic: str, complexity: str
) -> list[TrainingExample]:
    """Genera un ejemplo de entrenamiento con timeout."""
    prompt = f"""Genera exactamente {EXAMPLES_PER_BATCH} ejemplo de entrenamiento sobre: {topic}.

Complejidad: {complexity}.

El ejemplo debe tener:
- Un enunciado que suene como algo que dirÃ­a un dev o hacker en su dÃ­a a dÃ­a
- Razonamiento detallado paso a paso con contexto tÃ©cnico
- IdentificaciÃ³n correcta de Ã¡tomos y conectores
- La fÃ³rmula proposicional correcta en Unicode y ASCII

Â¡SÃ© creativo y tÃ©cnicamente preciso! Usa jerga real del campo."""

    result = await asyncio.wait_for(agent.run(prompt), timeout=180)
    return result.output.examples


async def main():
    parser = argparse.ArgumentParser(
        description="Genera dataset sintÃ©tico de lÃ³gica proposicional"
    )
    parser.add_argument(
        "--total", type=int, default=50, help="Total de ejemplos a generar"
    )
    parser.add_argument(
        "--output", type=str, default="dataset.json", help="Archivo de salida"
    )
    args = parser.parse_args()

    output_file = args.output
    total = args.total

    # Crear agente con DeepSeek V3 (~$0.002/ejemplo)
    agent = Agent(
        "deepseek:deepseek-chat",
        output_type=SyntheticDataset,
        system_prompt=SYSTEM_PROMPT,
        retries=5,
    )

    # Cargar progreso previo
    all_examples = load_progress(output_file)
    if all_examples:
        print(f"ğŸ“‚ Cargados {len(all_examples)} ejemplos previos desde {output_file}")

    remaining = total - len(all_examples)
    if remaining <= 0:
        print(f"âœ… Ya tienes {len(all_examples)}/{total} ejemplos. Nada que generar.")
        return

    batches_needed = (remaining + EXAMPLES_PER_BATCH - 1) // EXAMPLES_PER_BATCH
    print(
        f"ğŸš€ Generando ~{remaining} ejemplos restantes en ~{batches_needed} batches de {EXAMPLES_PER_BATCH}"
    )
    print(f"ğŸ“ Guardando en: {output_file}\n")

    errors = 0
    consecutive_errors = 0
    for i in range(batches_needed):
        if len(all_examples) >= total:
            break
        topic = random.choice(TOPICS)
        complexity = random.choice(COMPLEXITY_MIXES)

        print(
            f"ğŸ”„ Batch {i + 1}/{batches_needed} [{len(all_examples)}/{total}] {topic[:50]}... ({complexity})",
            end=" ",
            flush=True,
        )

        try:
            examples = await generate_one(agent, topic, complexity)
            all_examples.extend(examples)
            save_progress(all_examples, output_file)
            print(f"âœ…")
            consecutive_errors = 0

            # Liberar memoria cada 10 ejemplos
            if (i + 1) % 10 == 0:
                gc.collect()

            # Pausa entre llamadas para respetar rate limit (30 req/min)
            await asyncio.sleep(2.5)

        except Exception as e:
            errors += 1
            consecutive_errors += 1
            err_str = str(e)
            is_rate_limit = "429" in err_str or "rate limit" in err_str.lower()
            if is_rate_limit:
                wait = 15 * consecutive_errors
                print(f"â³ Rate limit, esperando {wait}s...")
                await asyncio.sleep(wait)
            else:
                print(f"âŒ ({consecutive_errors}/5) {err_str[:100]}")
            if consecutive_errors >= 5:
                print("\nâš ï¸ 5 errores consecutivos, deteniendo.")
                break
            continue

    # Resumen final
    print(f"\n{'=' * 60}")
    print(f"ğŸ‰ GeneraciÃ³n completada!")
    print(f"ğŸ“Š Total: {len(all_examples)} ejemplos")
    print(f"âŒ Errores: {errors}")
    print(f"ğŸ“ Guardado en: {output_file}")

    # EstadÃ­sticas
    from collections import Counter

    complexities = Counter(ex.complexity.value for ex in all_examples)
    print(f"\nğŸ“ˆ DistribuciÃ³n:")
    for comp, count in complexities.most_common():
        print(f"   {comp}: {count}")

    if all_examples:
        sample = random.choice(all_examples)
        print(f"\nğŸ“ Ejemplo aleatorio:")
        print(f"   Input: {sample.natural_language_input}")
        print(f"   FÃ³rmula: {sample.output.formula}")
        print(f"   ASCII: {sample.output.formula_ascii}")


if __name__ == "__main__":
    asyncio.run(main())
